{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6170f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class Operator(Enum):\n",
    "    ADD = auto()\n",
    "    MUL = auto()\n",
    "    POW = auto()\n",
    "    NEG = auto()\n",
    "\n",
    "    def __str__(self):\n",
    "        match self:\n",
    "            case Operator.ADD:\n",
    "                return '+'\n",
    "            case Operator.MUL:\n",
    "                return '*'\n",
    "            case Operator.POW:\n",
    "                return '^'\n",
    "            case Operator.NEG:\n",
    "                return '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a094178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize(tensor, graph='compute graph'):\n",
    "    dot = Digraph(comment=graph)\n",
    "    added_edges = set()\n",
    "\n",
    "    def add_node(x):\n",
    "        fillcolor = 'white' if x.requires_grad else 'lightcoral'\n",
    "        if graph == 'compute graph':\n",
    "            dot.node(str(id(x)), f\"{x.data:.3f}\", style='filled', fillcolor=fillcolor)\n",
    "        else:\n",
    "            dot.node(str(id(x)), f\"{x.grad:.3f}\", style='filled', fillcolor=fillcolor)\n",
    "    # add_node = lambda x: \n",
    "    add_op_node = lambda x: dot.node(str(id(x)), str(x.type))\n",
    "\n",
    "    def add_edge(start,end):\n",
    "        x = str(id(start))\n",
    "        y = str(id(end))\n",
    "        edge = (x,y)\n",
    "        if edge not in added_edges:\n",
    "            dot.edges([edge])\n",
    "            added_edges.add(edge)\n",
    "\n",
    "\n",
    "    def make_graph(t: Tensor):\n",
    "        add_node(t)\n",
    "        if t.op:\n",
    "            add_op_node(t.op)\n",
    "            if graph == 'compute graph':\n",
    "                add_edge(t.op, t)\n",
    "            else: \n",
    "                add_edge(t, t.op)\n",
    "\n",
    "            if t.op.left:\n",
    "                make_graph(t.op.left)\n",
    "                if graph == 'compute graph':\n",
    "                    add_edge(t.op.left, t.op)\n",
    "                else: \n",
    "                    add_edge(t.op, t.op.left)\n",
    "\n",
    "            if t.op.right:\n",
    "                make_graph(t.op.right)\n",
    "                if graph =='compute graph':\n",
    "                    add_edge(t.op.right, t.op)\n",
    "                else:\n",
    "                    add_edge(t.op, t.op.right)\n",
    "    make_graph(tensor)\n",
    "    display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca00bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "class Op:\n",
    "    def __init__(self, type: str, left, right=None):\n",
    "        self.type = type\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3aa9fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "@dataclass\n",
    "class Tensor:\n",
    "    data: float\n",
    "    op: Op | None = None\n",
    "    grad: float = 0.0\n",
    "    requires_grad: bool = True\n",
    "    # no_grad: bool = False\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_tensor(value, requires_grad=False):\n",
    "        return value if isinstance(value, Tensor) else Tensor(value, requires_grad=requires_grad)\n",
    "\n",
    "    def validate_arg(fn):\n",
    "        def wrapper(self, other):\n",
    "            other = Tensor.ensure_tensor(other, requires_grad=False)\n",
    "            return fn(self, other)\n",
    "        return wrapper\n",
    "\n",
    "    @validate_arg\n",
    "    def __add__(self, other):\n",
    "        n = self.data + other.data\n",
    "        op = Op(Operator.ADD, self, other)\n",
    "        return Tensor(n, op)\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    @validate_arg\n",
    "    def __mul__(self, other):\n",
    "        n = self.data * other.data\n",
    "        op = Op(Operator.MUL, self, other)\n",
    "        return Tensor(n, op)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    \n",
    "    @validate_arg\n",
    "    def __pow__(self, power):\n",
    "        try:\n",
    "            n = self.data ** power.data\n",
    "        except ZeroDivisionError:\n",
    "            n = float('nan')\n",
    "        op = Op(Operator.POW, self, power)\n",
    "        return Tensor(n, op)\n",
    "    \n",
    "    @validate_arg\n",
    "    def __rpow__(self, base):\n",
    "        return base ** self\n",
    "    \n",
    "    @validate_arg\n",
    "    def __sub__(self, other):\n",
    "        other.data = -other.data\n",
    "        return self + other\n",
    "    \n",
    "    @validate_arg\n",
    "    def __truediv__(self, other):\n",
    "        return self * other ** -1 \n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return other * self ** -1\n",
    "\n",
    "    def __neg__(self):\n",
    "        data = -self.data\n",
    "        op = Op(Operator.NEG, self)\n",
    "        return Tensor(data, op)\n",
    "\n",
    "    def backward(self):\n",
    "        self.grad += 1.0\n",
    "        self._backward()\n",
    "\n",
    "    def _backward(self):\n",
    "        op = self.op\n",
    "        if not op:\n",
    "            return\n",
    "        match op.type:\n",
    "            case Operator.ADD:\n",
    "                op.left.grad += self.grad\n",
    "                op.right.grad += self.grad\n",
    "\n",
    "            case Operator.MUL:\n",
    "                op.left.grad += self.grad * op.right.data \n",
    "                op.right.grad += self.grad * op.left.data\n",
    "\n",
    "            case Operator.POW:\n",
    "                n = op.right.data\n",
    "                op.left.grad += self.grad * n * op.left.data ** (n-1)\n",
    "\n",
    "                base = op.left.data\n",
    "                op.right.grad += self.grad * self.data * math.log(base)\n",
    "            case Operator.NEG:\n",
    "                assert op.right is None, \"Unary Operation can't have operands\"\n",
    "                op.left.grad += -self.grad\n",
    "\n",
    "\n",
    "        if op.left:\n",
    "            op.left._backward()\n",
    "        if op.right:\n",
    "            op.right._backward()\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Optimizer:\n",
    "    params: list[Tensor]\n",
    "    lr: float= 0.01\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            if param.requires_grad:\n",
    "                param.data = param.data - self.lr * param.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for t in self.params:\n",
    "            t.grad = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "4cc74e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(0,0), (0,1), (1,0), (1,1)]\n",
    "y = [0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "7c275b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+math.e**-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1a7141b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b6e46664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "class Linear:\n",
    "    def __init__(self, in_features:int , out_features: int, bias=True):\n",
    "        self.input = in_features\n",
    "        self.output = out_features\n",
    "        self.bias = bias\n",
    "\n",
    "        self.weights = [Tensor(random()) for _ in range(self.input * self.output)]\n",
    "        if bias:\n",
    "            self.bias = [Tensor(random()) for _ in range(self.output)]\n",
    "        else: \n",
    "            self.bias = [0]*len(self.output) # on the assumption that raw int value converted to Tensor are always with requires grad= False\n",
    "\n",
    "    def __call__(self, x: list):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x: list):\n",
    "        assert len(x[0]) == self.input, f\"Got {len(x)} features, expected {self.input}\"\n",
    "\n",
    "        output = []\n",
    "        dot_prod = lambda x, w, b: sum([xi * wi for xi, wi in zip(x,w)], b)\n",
    "\n",
    "        # the loop un-batches the input -- gets single input point at a time\n",
    "        for inp in x: \n",
    "            weight = chunks(self.weights, self.input) \n",
    "            out = [dot_prod(inp, w, b) for w, b in zip(weight, self.bias)]\n",
    "            output.append(out)\n",
    "        return output\n",
    "    def params(self):\n",
    "        return self.weights, self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6e446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
